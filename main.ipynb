{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import*\n",
    "from preprocessing import preprocessing,preprocessing2\n",
    "from feature_extraction import extract_features,read_images\n",
    "from training import *\n",
    "from performance import performance_analysis\n",
    "from itertools import compress\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vector_train=np.empty((0,4608))\n",
    "Y_train=np.array([])\n",
    "features_vector_test=np.empty((0,4608))\n",
    "Y_test=np.array([])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preRGB(img):\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    R=img[:,:,0]\n",
    "    G=img[:,:,1]\n",
    "    B=img[:,:,2]\n",
    "\n",
    "    BGR_Max=np.maximum.reduce([R,G,B])\n",
    "    BGR_Min=np.minimum.reduce([R,G,B])\n",
    "\n",
    "    Rule_1=np.logical_and.reduce([R>95,G>40,B>20,(BGR_Max-BGR_Min)>15,abs(R-G)>15,R>G,R>B])\n",
    "    Rule_2=np.logical_and.reduce([R>220,G>210,B>170,abs(R-G)<=15,R>B,G>B])\n",
    "\n",
    "    RGB_Rule=np.bitwise_or(Rule_1,Rule_2)\n",
    "    RGB_Rule=RGB_Rule*255\n",
    "\n",
    "\n",
    "    # Flip\n",
    "    sum_cols = np.sum(RGB_Rule,axis=0)\n",
    "\n",
    "    OCR=sum_cols\n",
    "    res=list(compress(range(len(sum_cols==np.max(OCR))),sum_cols==np.max(OCR)))\n",
    "\n",
    "    # print(np.sum(RGB_Rule!=0))\n",
    "    # print(np.sum(RGB_Rule!=255))\n",
    "    # print(np.shape(RGB_Rule)[0]*np.shape(RGB_Rule)[1])\n",
    "    # print(np.max(RGB_Rule))\n",
    "\n",
    "\n",
    "    if(res[0]<(np.shape(img)[1]/2)):\n",
    "        RGB_Rule=cv2.flip(RGB_Rule,1)\n",
    "\n",
    "    return RGB_Rule\n",
    "\n",
    "\n",
    "    # # Find Contours\n",
    "    # contours, hierarchy = cv2.findContours(\n",
    "    #     RGB_Rule, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    # # Get Largest Contour\n",
    "    # sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    # largest_contour = sorted_contours[0]\n",
    "\n",
    "    # # Binary_img_contours[Result]\n",
    "    # hand_contour = np.zeros((np.shape(img)[0], np.shape(img)[1], 1))\n",
    "    # cv2.drawContours(hand_contour, largest_contour, -1, 255, 10)\n",
    "\n",
    "    # return hand_contour\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def OCR(features_vector,img,name):\n",
    "    '''img:Binary Assume images are same size :D'''\n",
    "    sum_cols = np.sum(img,axis=0)\n",
    "    if(np.shape(sum_cols)[0]!=np.shape(features_vector)[1]):\n",
    "        print(\"Mismatch in Size\",name,\" has \",np.shape(sum_cols)[0] ,'while before has ',np.shape(features_vector)[1])\n",
    "        return features_vector\n",
    "    \n",
    "    features_vector=np.vstack([features_vector,sum_cols])\n",
    "    return features_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "#Training Data Set\n",
    "for i in range(0, 6):\n",
    "    print(i)\n",
    "    path_of_the_directory='../data_split/split/men/train/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/men/train/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    else:\n",
    "        shutil.rmtree(path_of_the_directory_result, ignore_errors=False, onerror=None)\n",
    "        os.mkdir(path_of_the_directory_result)\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str(filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preRGB(img)\n",
    "        features_vector_train=OCR(features_vector_train,binary_hand,filename)\n",
    "        Y_train=np.append(Y_train,i)\n",
    "        # binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        # binary_hand=preprocessing2(img)\n",
    "\n",
    "        # plt.imsave(path_of_the_directory_result+filename, np.array(binary_hand), cmap=cm.gray)\n",
    "\n",
    "        # cv2.imwrite(path_of_the_directory_result+filename,binary_hand)\n",
    "\n",
    "    path_of_the_directory='../data_split/split/women/train/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/women/train/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str(filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preRGB(img)\n",
    "        features_vector_train=OCR(features_vector_train,binary_hand,filename)\n",
    "        Y_train=np.append(Y_train,i)\n",
    "        # binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        # binary_hand=preprocessing2(img)\n",
    "\n",
    "        # plt.imsave(path_of_the_directory_result+filename, np.array(binary_hand), cmap=cm.gray)\n",
    "\n",
    "        # cv2.imwrite(path_of_the_directory_result+filename,binary_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating df object with columns specified   \n",
    "# csv = pd.DataFrame(features_vector_train, columns =list(np.shape(features_vector_train)[1])) \n",
    "\n",
    "# # #Adding Lables to the Data Frame\n",
    "# csv.insert(0, \"class\", Y_train)\n",
    "# # print(csv)\n",
    "\n",
    "\n",
    "# csv.to_csv (r'../outputs/train.csv', index = None)\n",
    "\n",
    "# print(np.shape(features_vector_train))\n",
    "\n",
    "\n",
    "\n",
    "np.save('../outputs/train_x',features_vector_train)\n",
    "np.save('../outputs/train_y',Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "The new directory is created!\n",
      "1\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "2\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "3\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "4\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "5\n",
      "The new directory is created!\n",
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "#Testing Data Set\n",
    "for i in range(0, 6):\n",
    "    print(i)\n",
    "    path_of_the_directory='../data_split/split/men/test/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/men/test/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str(filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preRGB(img)\n",
    "        features_vector_test=OCR(features_vector_test,binary_hand,filename)\n",
    "        Y_test=np.append(Y_test,i)\n",
    "        # binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        # binary_hand=preprocessing2(img)\n",
    "        # cv2.imwrite(path_of_the_directory_result+filename,binary_hand)\n",
    "\n",
    "    path_of_the_directory='../data_split/split/women/test/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/women/test/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str( filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preRGB(img)\n",
    "        features_vector_test=OCR(features_vector_test,binary_hand,filename)\n",
    "        Y_test=np.append(Y_test,i)\n",
    "        # binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        # binary_hand=preprocessing2(img)\n",
    "        # cv2.imwrite(path_of_the_directory_result+filename,binary_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv = pd.DataFrame(features_vector_test, columns =list(np.shape(features_vector_test)[1])) \n",
    "\n",
    "# # #Adding Lables to the Data Frame\n",
    "# csv.insert(0, \"class\", Y_train)\n",
    "# # print(csv)\n",
    "\n",
    "\n",
    "# csv.to_csv (r'../outputs/train.csv', index = None)\n",
    "\n",
    "\n",
    "np.save('../outputs/test_x',features_vector_test)\n",
    "np.save('../outputs/test_y',Y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step(1) Read Images\n",
    "path='../outputs/preprocessing_output/'\n",
    "train_images=read_images(path,type=\"train\")\n",
    "\n",
    "print(\"Read 0:\", np.shape(train_images['0']))\n",
    "print(\"Read 1:\", np.shape(train_images['1']))\n",
    "print(\"Read 2:\", np.shape(train_images['2']))\n",
    "print(\"Read 3:\", np.shape(train_images['3']))\n",
    "print(\"Read 4:\", np.shape(train_images['4']))\n",
    "print(\"Read 5:\", np.shape(train_images['5']))\n",
    "\n",
    "\n",
    "test_images=read_images(path,type=\"test\")\n",
    "\n",
    "print(\"Read 0:\", np.shape(test_images['0']))\n",
    "print(\"Read 1:\", np.shape(test_images['1']))\n",
    "print(\"Read 2:\", np.shape(test_images['2']))\n",
    "print(\"Read 3:\", np.shape(test_images['3']))\n",
    "print(\"Read 4:\", np.shape(test_images['4']))\n",
    "print(\"Read 5:\", np.shape(test_images['5']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clusters=8\n",
    "path='../outputs/preprocessing_output/'\n",
    "X_train,Y_train,visual_words=extract_features(path,number_of_clusters,debug=True,images=train_images,train=True,visual_words=None)\n",
    "# print(np.shape(visual_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating df object with columns specified   \n",
    "csv = pd.DataFrame(X_train, columns =list(range(number_of_clusters))) \n",
    "\n",
    "# #Adding Lables to the Data Frame\n",
    "csv.insert(0, \"class\", Y_train)\n",
    "# print(csv)\n",
    "\n",
    "\n",
    "csv.to_csv (r'../outputs/train.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../outputs/preprocessing_output/'\n",
    "X_test,Y_test,visual_words=extract_features(path,clusters=None,debug=True,images=test_images,train=False,visual_words=visual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating df object with columns specified   \n",
    "csv = pd.DataFrame(X_test, columns =list(range(number_of_clusters))) \n",
    "\n",
    "#Adding Lables to the Data Frame\n",
    "\n",
    "csv.insert(0, \"class\", Y_test)\n",
    "print(csv)\n",
    "\n",
    "\n",
    "csv.to_csv (r'../outputs/test.csv', index = None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from CVS File\n",
    "df = pd.read_csv('../outputs/train.csv')\n",
    "# print(df)\n",
    "\n",
    "\n",
    "classes_train=df.loc[:,\"class\"]\n",
    "# classes_train = classes_train.to_numpy()\n",
    "# print(classes_train)\n",
    "# print(np.shape(classes_train))\n",
    "\n",
    "\n",
    "features_train=df.loc[:, df.columns != 'class']\n",
    "# features_train = features_train.to_numpy()\n",
    "# print(features_train)\n",
    "print(np.shape(features_train))\n",
    "\n",
    "# Read from CVS File\n",
    "df = pd.read_csv('../outputs/test.csv')\n",
    "# print(df)\n",
    "\n",
    "\n",
    "classes_test=df.loc[:,\"class\"]\n",
    "# classes_test = classes_test.to_numpy()\n",
    "# print(classes_test)\n",
    "# print(np.shape(classes_test))\n",
    "\n",
    "\n",
    "features_test=df.loc[:, df.columns != 'class']\n",
    "# features_test = features_test.to_numpy()\n",
    "# print(features_test)\n",
    "print(np.shape(features_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Visual Words(BoVW)\n",
    "##### SIFT TO SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6717948717948717\n",
      "0.40512820512820513\n"
     ]
    }
   ],
   "source": [
    "# prediction, actual = train_randomforest(features_train,classes_train,features_test,classes_test)\n",
    "# prediction, actual = train_svm(features_train,classes_train,features_test,classes_test)\n",
    "\n",
    "prediction, actual = train_randomforest(features_vector_train,Y_train,features_vector_test,Y_test)\n",
    "accuracy = performance_analysis(prediction,actual)\n",
    "print(accuracy)\n",
    "prediction, actual = train_svm(features_vector_train,Y_train,features_vector_test,Y_test)\n",
    "accuracy = performance_analysis(prediction,actual)\n",
    "print(accuracy)\n",
    "\n",
    "# prediction, actual = train_svm(features_train,classes_train,features_test,classes_test)\n",
    "\n",
    "\n",
    "\n",
    "# print(prediction)\n",
    "# print(actual)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = performance_analysis(prediction,actual)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
