{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import*\n",
    "from preprocessing import preprocessing\n",
    "from preprocessing import preprocessing2\n",
    "from preprocessing import preprocessing3\n",
    "from preprocessing import preprocessing4\n",
    "from feature_extraction import extract_features,read_images\n",
    "from training import *\n",
    "from performance import performance_analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Training Data Set\n",
    "# for i in range(0, 6):\n",
    "#     print(i)\n",
    "#     path_of_the_directory='../data_simple/split/men/train/'+str(i)+'/'\n",
    "#     path_of_the_directory_result='../outputs/preprocessing_output/men/train/'+str(i)+'/'\n",
    "#     isExist = os.path.exists(path_of_the_directory_result)\n",
    "#     if not isExist:\n",
    "#         os.makedirs(path_of_the_directory_result)\n",
    "#         print(\"The new directory is created!\")\n",
    "#     else:\n",
    "#         shutil.rmtree(path_of_the_directory_result, ignore_errors=False, onerror=None)\n",
    "#         os.mkdir(path_of_the_directory_result)\n",
    "#     # ind=0\n",
    "#     for filename in os.listdir(path_of_the_directory):\n",
    "#         # if(ind>20):\n",
    "#         #     break\n",
    "#         # ind=ind+1\n",
    "#         img = cv2.imread(path_of_the_directory+str(filename))\n",
    "#         if img is None:\n",
    "#             continue\n",
    "\n",
    "#         # Skin Masks\n",
    "#         binary_hand=preprocessing4(img)\n",
    "#         cv2.imwrite(path_of_the_directory_result+filename,binary_hand)\n",
    "\n",
    "#     path_of_the_directory='../data_simple/split/women/train/'+str(i)+'/'\n",
    "#     path_of_the_directory_result='../outputs/preprocessing_output/women/train/'+str(i)+'/'\n",
    "#     isExist = os.path.exists(path_of_the_directory_result)\n",
    "#     if not isExist:\n",
    "#         os.makedirs(path_of_the_directory_result)\n",
    "#         print(\"The new directory is created!\")\n",
    "#     # ind=0\n",
    "#     for filename in os.listdir(path_of_the_directory):\n",
    "#         # if(ind>20):\n",
    "#         #     break\n",
    "#         # ind=ind+1\n",
    "#         img = cv2.imread(path_of_the_directory+str( filename))\n",
    "#         if img is None:\n",
    "#             continue\n",
    "\n",
    "#         # Skin Masks\n",
    "#         binary_hand=preprocessing4(img)\n",
    "#         cv2.imwrite(path_of_the_directory_result+filename,binary_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Testing Data Set\n",
    "# for i in range(0, 6):\n",
    "#     print(i)\n",
    "#     path_of_the_directory='../data_simple/split/men/test/'+str(i)+'/'\n",
    "#     path_of_the_directory_result='../outputs/preprocessing_output/men/test/'+str(i)+'/'\n",
    "#     isExist = os.path.exists(path_of_the_directory_result)\n",
    "#     if not isExist:\n",
    "#         os.makedirs(path_of_the_directory_result)\n",
    "#         print(\"The new directory is created!\")\n",
    "#     # ind=0\n",
    "#     for filename in os.listdir(path_of_the_directory):\n",
    "#         # if(ind>20):\n",
    "#         #     break\n",
    "#         # ind=ind+1\n",
    "#         img = cv2.imread(path_of_the_directory+str(filename))\n",
    "#         if img is None:\n",
    "#             continue\n",
    "\n",
    "#         # Skin Masks\n",
    "#         binary_hand=preprocessing4(img)\n",
    "#         cv2.imwrite(path_of_the_directory_result+filename,binary_hand)\n",
    "\n",
    "#     path_of_the_directory='../data_simple/split/women/test/'+str(i)+'/'\n",
    "#     path_of_the_directory_result='../outputs/preprocessing_output/women/test/'+str(i)+'/'\n",
    "#     isExist = os.path.exists(path_of_the_directory_result)\n",
    "#     if not isExist:\n",
    "#         os.makedirs(path_of_the_directory_result)\n",
    "#         print(\"The new directory is created!\")\n",
    "#     # ind=0\n",
    "#     for filename in os.listdir(path_of_the_directory):\n",
    "#         # if(ind>20):\n",
    "#         #     break\n",
    "#         # ind=ind+1\n",
    "#         img = cv2.imread(path_of_the_directory+str( filename))\n",
    "#         if img is None:\n",
    "#             continue\n",
    "\n",
    "#         # Skin Masks\n",
    "#         binary_hand=preprocessing4(img)\n",
    "#         cv2.imwrite(path_of_the_directory_result+filename,binary_hand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Read 0: (200, 2304, 1296)\n",
      "Read 1: (210, 2304, 1296)\n",
      "Read 2: (215, 2304, 1296)\n",
      "Read 3: (221, 2304, 1296)\n",
      "Read 4: (210, 2304, 1296)\n",
      "Read 5: (217, 2304, 1296)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Read 0: (30, 2304, 1296)\n",
      "Read 1: (31, 2304, 1296)\n",
      "Read 2: (34, 2304, 1296)\n",
      "Read 3: (34, 2304, 1296)\n",
      "Read 4: (33, 2304, 1296)\n",
      "Read 5: (33, 2304, 1296)\n"
     ]
    }
   ],
   "source": [
    "# Step(1) Read Images\n",
    "path='../outputs/preprocessing_output/'\n",
    "train_images=read_images(path,type=\"train\")\n",
    "\n",
    "print(\"Read 0:\", np.shape(train_images['0']))\n",
    "print(\"Read 1:\", np.shape(train_images['1']))\n",
    "print(\"Read 2:\", np.shape(train_images['2']))\n",
    "print(\"Read 3:\", np.shape(train_images['3']))\n",
    "print(\"Read 4:\", np.shape(train_images['4']))\n",
    "print(\"Read 5:\", np.shape(train_images['5']))\n",
    "\n",
    "\n",
    "test_images=read_images(path,type=\"test\")\n",
    "\n",
    "print(\"Read 0:\", np.shape(test_images['0']))\n",
    "print(\"Read 1:\", np.shape(test_images['1']))\n",
    "print(\"Read 2:\", np.shape(test_images['2']))\n",
    "print(\"Read 3:\", np.shape(test_images['3']))\n",
    "print(\"Read 4:\", np.shape(test_images['4']))\n",
    "print(\"Read 5:\", np.shape(test_images['5']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_of_clusters=8\n",
    "# path='../outputs/preprocessing_output/'\n",
    "# X_train,Y_train,visual_words=extract_features(path,number_of_clusters,debug=True,images=train_images,train=True,visual_words=None, orb_params=[1000, 1.3, 4])\n",
    "# # print(np.shape(visual_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#Trying HOG\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for i in range(6):\n",
    "    print(i)\n",
    "    for img in train_images[str(i)]:\n",
    "            img = resize(img, (64*4, 128*4))\n",
    "            fd, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "            X_train.append(fd)\n",
    "            Y_train.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(i)\n",
    "    for img in test_images[str(i)]:\n",
    "            img = resize(img, (64*4, 128*4))\n",
    "            fd, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "            X_test.append(fd)\n",
    "            Y_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating df object with columns specified   \n",
    "csv = pd.DataFrame(X_train, columns =list(range(number_of_clusters))) \n",
    "\n",
    "# #Adding Lables to the Data Frame\n",
    "csv.insert(0, \"class\", Y_train)\n",
    "# print(csv)\n",
    "\n",
    "\n",
    "csv.to_csv (r'../outputs/train.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../outputs/preprocessing_output/'\n",
    "X_test,Y_test,visual_words=extract_features(path,clusters=None,debug=True,images=test_images,train=False,visual_words=visual_words, orb_params=[1000, 1.3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating df object with columns specified   \n",
    "csv = pd.DataFrame(X_test, columns =list(range(number_of_clusters))) \n",
    "\n",
    "#Adding Lables to the Data Frame\n",
    "\n",
    "csv.insert(0, \"class\", Y_test)\n",
    "print(csv)\n",
    "\n",
    "\n",
    "csv.to_csv (r'../outputs/test.csv', index = None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from CVS File\n",
    "df = pd.read_csv('../outputs/train.csv')\n",
    "# print(df)\n",
    "\n",
    "\n",
    "classes_train=df.loc[:,\"class\"]\n",
    "# classes_train = classes_train.to_numpy()\n",
    "# print(classes_train)\n",
    "# print(np.shape(classes_train))\n",
    "\n",
    "\n",
    "features_train=df.loc[:, df.columns != 'class']\n",
    "# features_train = features_train.to_numpy()\n",
    "# print(features_train)\n",
    "print(np.shape(features_train))\n",
    "\n",
    "# Read from CVS File\n",
    "df = pd.read_csv('../outputs/test.csv')\n",
    "# print(df)\n",
    "\n",
    "\n",
    "classes_test=df.loc[:,\"class\"]\n",
    "# classes_test = classes_test.to_numpy()\n",
    "# print(classes_test)\n",
    "# print(np.shape(classes_test))\n",
    "\n",
    "\n",
    "features_test=df.loc[:, df.columns != 'class']\n",
    "# features_test = features_test.to_numpy()\n",
    "# print(features_test)\n",
    "print(np.shape(features_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Visual Words(BoVW)\n",
    "##### SIFT TO SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction, actual = train_randomforest(features_train,classes_train,features_test,classes_test, n_estimators=10000, criterion='entropy')\n",
    "# prediction, actual = train_svm(features_train,classes_train,features_test,classes_test)\n",
    "# train_mlp(features_train,classes_train,features_test,classes_test)\n",
    "\n",
    "# train_mlp(X_train,Y_train,X_test,Y_test) #FAILED\n",
    "prediction, actual = train_svm(X_train,Y_train,X_test,Y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6256410256410256\n"
     ]
    }
   ],
   "source": [
    "accuracy = performance_analysis(prediction,actual)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5025641025641026\n"
     ]
    }
   ],
   "source": [
    "prediction, actual = train_randomforest(X_train,Y_train,X_test,Y_test)\n",
    "accuracy = performance_analysis(prediction,actual)\n",
    "print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Up Model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "filename = \"Trained_SVM.joblib\"\n",
    "joblib.dump(model, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
