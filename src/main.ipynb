{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import*\n",
    "from preprocessing import preprocessing\n",
    "from feature_extraction import extract_features,read_images\n",
    "from training import *\n",
    "from performance import performance_analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#Training Data Set\n",
    "for i in range(0, 6):\n",
    "    print(i)\n",
    "    path_of_the_directory='../data_simple/split/men/train/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/men/train/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    else:\n",
    "        shutil.rmtree(path_of_the_directory_result, ignore_errors=False, onerror=None)\n",
    "        os.mkdir(path_of_the_directory_result)\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str(filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)\n",
    "\n",
    "    path_of_the_directory='../data_simple/split/women/train/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/women/train/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str( filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "1\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "2\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "3\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "4\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "5\n",
      "The new directory is created!\n",
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "#Testing Data Set\n",
    "for i in range(0, 6):\n",
    "    print(i)\n",
    "    path_of_the_directory='../data_simple/split/men/test/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/men/test/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str(filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)\n",
    "\n",
    "    path_of_the_directory='../data_simple/split/women/test/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/women/test/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str( filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Read 0: (39, 2592, 4608)\n",
      "Read 1: (39, 2592, 4608)\n",
      "Read 2: (33, 2592, 4608)\n",
      "Read 3: (33, 2592, 4608)\n",
      "Read 4: (37, 2592, 4608)\n",
      "Read 5: (42, 2592, 4608)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Read 0: (9, 2592, 4608)\n",
      "Read 1: (9, 2592, 4608)\n",
      "Read 2: (8, 2592, 4608)\n",
      "Read 3: (9, 2592, 4608)\n",
      "Read 4: (8, 2592, 4608)\n",
      "Read 5: (8, 2592, 4608)\n"
     ]
    }
   ],
   "source": [
    "# Step(1) Read Images\n",
    "path='../outputs/preprocessing_output/'\n",
    "train_images=read_images(path,type=\"train\")\n",
    "\n",
    "print(\"Read 0:\", np.shape(train_images['0']))\n",
    "print(\"Read 1:\", np.shape(train_images['1']))\n",
    "print(\"Read 2:\", np.shape(train_images['2']))\n",
    "print(\"Read 3:\", np.shape(train_images['3']))\n",
    "print(\"Read 4:\", np.shape(train_images['4']))\n",
    "print(\"Read 5:\", np.shape(train_images['5']))\n",
    "\n",
    "\n",
    "test_images=read_images(path,type=\"test\")\n",
    "\n",
    "print(\"Read 0:\", np.shape(test_images['0']))\n",
    "print(\"Read 1:\", np.shape(test_images['1']))\n",
    "print(\"Read 2:\", np.shape(test_images['2']))\n",
    "print(\"Read 3:\", np.shape(test_images['3']))\n",
    "print(\"Read 4:\", np.shape(test_images['4']))\n",
    "print(\"Read 5:\", np.shape(test_images['5']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift_descriptors for 0\n",
      "0 has: 824Keypoints\n",
      "1 has: 709Keypoints\n",
      "2 has: 811Keypoints\n",
      "3 has: 724Keypoints\n",
      "4 has: 695Keypoints\n",
      "5 has: 1038Keypoints\n",
      "6 has: 844Keypoints\n",
      "7 has: 864Keypoints\n",
      "8 has: 1041Keypoints\n",
      "9 has: 630Keypoints\n",
      "10 has: 716Keypoints\n",
      "11 has: 633Keypoints\n",
      "12 has: 655Keypoints\n",
      "13 has: 508Keypoints\n",
      "14 has: 640Keypoints\n",
      "15 has: 695Keypoints\n",
      "16 has: 512Keypoints\n",
      "17 has: 734Keypoints\n",
      "18 has: 626Keypoints\n",
      "19 has: 706Keypoints\n",
      "20 has: 810Keypoints\n",
      "21 has: 367Keypoints\n",
      "22 has: 738Keypoints\n",
      "23 has: 1536Keypoints\n",
      "24 has: 847Keypoints\n",
      "25 has: 964Keypoints\n",
      "26 has: 616Keypoints\n",
      "27 has: 815Keypoints\n",
      "28 has: 546Keypoints\n",
      "29 has: 584Keypoints\n",
      "30 has: 729Keypoints\n",
      "31 has: 518Keypoints\n",
      "32 has: 521Keypoints\n",
      "33 has: 475Keypoints\n",
      "34 has: 739Keypoints\n",
      "35 has: 588Keypoints\n",
      "36 has: 495Keypoints\n",
      "37 has: 664Keypoints\n",
      "38 has: 455Keypoints\n",
      "sift_descriptors for 1\n",
      "0 has: 546Keypoints\n",
      "1 has: 712Keypoints\n",
      "2 has: 713Keypoints\n",
      "3 has: 747Keypoints\n",
      "4 has: 739Keypoints\n",
      "5 has: 1019Keypoints\n",
      "6 has: 547Keypoints\n",
      "7 has: 786Keypoints\n",
      "8 has: 527Keypoints\n",
      "9 has: 541Keypoints\n",
      "10 has: 848Keypoints\n",
      "11 has: 769Keypoints\n",
      "12 has: 829Keypoints\n",
      "13 has: 621Keypoints\n",
      "14 has: 934Keypoints\n",
      "15 has: 600Keypoints\n",
      "16 has: 760Keypoints\n",
      "17 has: 636Keypoints\n",
      "18 has: 971Keypoints\n",
      "19 has: 566Keypoints\n",
      "20 has: 580Keypoints\n",
      "21 has: 638Keypoints\n",
      "22 has: 729Keypoints\n",
      "23 has: 624Keypoints\n",
      "24 has: 415Keypoints\n",
      "25 has: 1014Keypoints\n",
      "26 has: 595Keypoints\n",
      "27 has: 642Keypoints\n",
      "28 has: 832Keypoints\n",
      "29 has: 699Keypoints\n",
      "30 has: 542Keypoints\n",
      "31 has: 489Keypoints\n",
      "32 has: 654Keypoints\n",
      "33 has: 1126Keypoints\n",
      "34 has: 615Keypoints\n",
      "35 has: 941Keypoints\n",
      "36 has: 685Keypoints\n",
      "37 has: 670Keypoints\n",
      "38 has: 708Keypoints\n",
      "sift_descriptors for 2\n",
      "0 has: 686Keypoints\n",
      "1 has: 598Keypoints\n",
      "2 has: 789Keypoints\n",
      "3 has: 1272Keypoints\n",
      "4 has: 1178Keypoints\n",
      "5 has: 1504Keypoints\n",
      "6 has: 570Keypoints\n",
      "7 has: 643Keypoints\n",
      "8 has: 889Keypoints\n",
      "9 has: 720Keypoints\n",
      "10 has: 692Keypoints\n",
      "11 has: 686Keypoints\n",
      "12 has: 740Keypoints\n",
      "13 has: 619Keypoints\n",
      "14 has: 680Keypoints\n",
      "15 has: 613Keypoints\n",
      "16 has: 1427Keypoints\n",
      "17 has: 619Keypoints\n",
      "18 has: 749Keypoints\n",
      "19 has: 740Keypoints\n",
      "20 has: 621Keypoints\n",
      "21 has: 915Keypoints\n",
      "22 has: 792Keypoints\n",
      "23 has: 510Keypoints\n",
      "24 has: 840Keypoints\n",
      "25 has: 506Keypoints\n",
      "26 has: 1082Keypoints\n",
      "27 has: 713Keypoints\n",
      "28 has: 811Keypoints\n",
      "29 has: 585Keypoints\n",
      "30 has: 597Keypoints\n",
      "31 has: 496Keypoints\n",
      "32 has: 705Keypoints\n",
      "sift_descriptors for 3\n",
      "0 has: 834Keypoints\n",
      "1 has: 1071Keypoints\n",
      "2 has: 590Keypoints\n",
      "3 has: 551Keypoints\n",
      "4 has: 760Keypoints\n",
      "5 has: 854Keypoints\n",
      "6 has: 499Keypoints\n",
      "7 has: 883Keypoints\n",
      "8 has: 1126Keypoints\n",
      "9 has: 726Keypoints\n",
      "10 has: 705Keypoints\n",
      "11 has: 586Keypoints\n",
      "12 has: 854Keypoints\n",
      "13 has: 727Keypoints\n",
      "14 has: 791Keypoints\n",
      "15 has: 758Keypoints\n",
      "16 has: 822Keypoints\n",
      "17 has: 900Keypoints\n",
      "18 has: 536Keypoints\n",
      "19 has: 778Keypoints\n",
      "20 has: 1781Keypoints\n",
      "21 has: 1283Keypoints\n",
      "22 has: 541Keypoints\n",
      "23 has: 767Keypoints\n",
      "24 has: 670Keypoints\n",
      "25 has: 805Keypoints\n",
      "26 has: 1112Keypoints\n",
      "27 has: 677Keypoints\n",
      "28 has: 699Keypoints\n",
      "29 has: 751Keypoints\n",
      "30 has: 688Keypoints\n",
      "31 has: 774Keypoints\n",
      "32 has: 1431Keypoints\n",
      "sift_descriptors for 4\n",
      "0 has: 897Keypoints\n",
      "1 has: 748Keypoints\n",
      "2 has: 390Keypoints\n",
      "3 has: 725Keypoints\n",
      "4 has: 618Keypoints\n",
      "5 has: 814Keypoints\n",
      "6 has: 1221Keypoints\n",
      "7 has: 1343Keypoints\n",
      "8 has: 789Keypoints\n",
      "9 has: 934Keypoints\n",
      "10 has: 1411Keypoints\n",
      "11 has: 747Keypoints\n",
      "12 has: 671Keypoints\n",
      "13 has: 1222Keypoints\n",
      "14 has: 1170Keypoints\n",
      "15 has: 1053Keypoints\n",
      "16 has: 926Keypoints\n",
      "17 has: 1039Keypoints\n",
      "18 has: 666Keypoints\n",
      "19 has: 831Keypoints\n",
      "20 has: 1791Keypoints\n",
      "21 has: 1083Keypoints\n",
      "22 has: 651Keypoints\n",
      "23 has: 798Keypoints\n",
      "24 has: 549Keypoints\n",
      "25 has: 568Keypoints\n",
      "26 has: 982Keypoints\n",
      "27 has: 706Keypoints\n",
      "28 has: 799Keypoints\n",
      "29 has: 529Keypoints\n",
      "30 has: 757Keypoints\n",
      "31 has: 846Keypoints\n",
      "32 has: 725Keypoints\n",
      "33 has: 1448Keypoints\n",
      "34 has: 959Keypoints\n",
      "35 has: 1171Keypoints\n",
      "36 has: 586Keypoints\n",
      "sift_descriptors for 5\n",
      "0 has: 1275Keypoints\n",
      "1 has: 982Keypoints\n",
      "2 has: 1082Keypoints\n",
      "3 has: 1253Keypoints\n",
      "4 has: 1039Keypoints\n",
      "5 has: 918Keypoints\n",
      "6 has: 1092Keypoints\n",
      "7 has: 938Keypoints\n",
      "8 has: 74Keypoints\n",
      "9 has: 1096Keypoints\n",
      "10 has: 1037Keypoints\n",
      "11 has: 743Keypoints\n",
      "12 has: 796Keypoints\n",
      "13 has: 998Keypoints\n",
      "14 has: 504Keypoints\n",
      "15 has: 766Keypoints\n",
      "16 has: 854Keypoints\n",
      "17 has: 587Keypoints\n",
      "18 has: 621Keypoints\n",
      "19 has: 969Keypoints\n",
      "20 has: 942Keypoints\n",
      "21 has: 874Keypoints\n",
      "22 has: 827Keypoints\n",
      "23 has: 737Keypoints\n",
      "24 has: 902Keypoints\n",
      "25 has: 1059Keypoints\n",
      "26 has: 896Keypoints\n",
      "27 has: 729Keypoints\n",
      "28 has: 662Keypoints\n",
      "29 has: 869Keypoints\n",
      "30 has: 841Keypoints\n",
      "31 has: 989Keypoints\n",
      "32 has: 1001Keypoints\n",
      "33 has: 942Keypoints\n",
      "34 has: 1001Keypoints\n",
      "35 has: 729Keypoints\n",
      "36 has: 1086Keypoints\n",
      "37 has: 971Keypoints\n",
      "38 has: 990Keypoints\n",
      "39 has: 679Keypoints\n",
      "40 has: 1220Keypoints\n",
      "41 has: 874Keypoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (39,)\n",
      "1 (39,)\n",
      "2 (33,)\n",
      "3 (33,)\n",
      "4 (37,)\n",
      "5 (42,)\n"
     ]
    }
   ],
   "source": [
    "number_of_clusters=8\n",
    "path='../outputs/preprocessing_output/'\n",
    "X_train,Y_train,visual_words=extract_features(path,number_of_clusters,debug=True,images=train_images,train=True,visual_words=None)\n",
    "# print(np.shape(visual_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating df object with columns specified   \n",
    "csv = pd.DataFrame(X_train, columns =list(range(number_of_clusters))) \n",
    "\n",
    "# #Adding Lables to the Data Frame\n",
    "csv.insert(0, \"class\", Y_train)\n",
    "# print(csv)\n",
    "\n",
    "\n",
    "csv.to_csv (r'../outputs/train.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift_descriptors for 0\n",
      "0 has: 588Keypoints\n",
      "1 has: 909Keypoints\n",
      "2 has: 459Keypoints\n",
      "3 has: 1421Keypoints\n",
      "4 has: 1043Keypoints\n",
      "5 has: 456Keypoints\n",
      "6 has: 679Keypoints\n",
      "7 has: 373Keypoints\n",
      "8 has: 656Keypoints\n",
      "sift_descriptors for 1\n",
      "0 has: 627Keypoints\n",
      "1 has: 726Keypoints\n",
      "2 has: 292Keypoints\n",
      "3 has: 327Keypoints\n",
      "4 has: 1215Keypoints\n",
      "5 has: 943Keypoints\n",
      "6 has: 74Keypoints\n",
      "7 has: 522Keypoints\n",
      "8 has: 747Keypoints\n",
      "sift_descriptors for 2\n",
      "0 has: 687Keypoints\n",
      "1 has: 512Keypoints\n",
      "2 has: 204Keypoints\n",
      "3 has: 736Keypoints\n",
      "4 has: 636Keypoints\n",
      "5 has: 670Keypoints\n",
      "6 has: 973Keypoints\n",
      "7 has: 837Keypoints\n",
      "sift_descriptors for 3\n",
      "0 has: 469Keypoints\n",
      "1 has: 533Keypoints\n",
      "2 has: 1303Keypoints\n",
      "3 has: 2171Keypoints\n",
      "4 has: 886Keypoints\n",
      "5 has: 832Keypoints\n",
      "6 has: 843Keypoints\n",
      "7 has: 638Keypoints\n",
      "8 has: 808Keypoints\n",
      "sift_descriptors for 4\n",
      "0 has: 777Keypoints\n",
      "1 has: 862Keypoints\n",
      "2 has: 806Keypoints\n",
      "3 has: 1233Keypoints\n",
      "4 has: 218Keypoints\n",
      "5 has: 741Keypoints\n",
      "6 has: 58Keypoints\n",
      "7 has: 646Keypoints\n",
      "sift_descriptors for 5\n",
      "0 has: 749Keypoints\n",
      "1 has: 850Keypoints\n",
      "2 has: 852Keypoints\n",
      "3 has: 1424Keypoints\n",
      "4 has: 707Keypoints\n",
      "5 has: 700Keypoints\n",
      "6 has: 519Keypoints\n",
      "7 has: 776Keypoints\n",
      "0 (9,)\n",
      "1 (9,)\n",
      "2 (8,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 (9,)\n",
      "4 (8,)\n",
      "5 (8,)\n"
     ]
    }
   ],
   "source": [
    "path='../outputs/preprocessing_output/'\n",
    "X_test,Y_test,visual_words=extract_features(path,clusters=None,debug=True,images=test_images,train=False,visual_words=visual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class      0      1      2      3      4      5      6      7\n",
      "0      0   51.0  140.0   41.0   55.0   83.0  105.0   51.0   62.0\n",
      "1      0  111.0  106.0   59.0  119.0  116.0  172.0  115.0  111.0\n",
      "2      0   77.0   32.0   22.0   75.0   46.0   99.0   74.0   34.0\n",
      "3      0  174.0  185.0  101.0  186.0  176.0  279.0  179.0  141.0\n",
      "4      0   71.0  270.0   91.0   94.0  146.0  182.0   70.0  119.0\n",
      "5      0   59.0   49.0   36.0   64.0   55.0   95.0   59.0   39.0\n",
      "6      0   44.0  221.0   50.0   62.0   76.0  102.0   37.0   87.0\n",
      "7      0   45.0   49.0   26.0   48.0   44.0   77.0   47.0   37.0\n",
      "8      0   26.0  194.0   53.0   40.0  135.0   93.0   31.0   84.0\n",
      "9      1   41.0  234.0   32.0   61.0   54.0   91.0   56.0   58.0\n",
      "10     1   86.0  121.0   49.0   95.0   70.0  139.0   94.0   72.0\n",
      "11     1   51.0   16.0   24.0   41.0   23.0   59.0   55.0   23.0\n",
      "12     1   36.0   35.0   26.0   52.0   36.0   72.0   49.0   21.0\n",
      "13     1  115.0  232.0   88.0  133.0  166.0  189.0  138.0  154.0\n",
      "14     1   78.0  188.0   80.0   93.0  111.0  164.0   95.0  134.0\n",
      "15     1   11.0   10.0    3.0   11.0    4.0   12.0   12.0   11.0\n",
      "16     1   30.0  255.0   25.0   33.0   43.0   57.0   29.0   50.0\n",
      "17     1   50.0  240.0   56.0   58.0  109.0  115.0   47.0   72.0\n",
      "18     2   14.0  354.0   48.0   17.0   63.0   76.0   11.0  104.0\n",
      "19     2   17.0  309.0   30.0   20.0   43.0   39.0   20.0   34.0\n",
      "20     2   26.0   14.0   15.0   23.0   38.0   40.0   24.0   24.0\n",
      "21     2   61.0  109.0   65.0   79.0  138.0  145.0   65.0   74.0\n",
      "22     2   46.0  137.0   53.0   57.0   94.0  104.0   68.0   77.0\n",
      "23     2   40.0  287.0   33.0   47.0   84.0   76.0   40.0   63.0\n",
      "24     2   90.0  215.0   75.0   99.0  135.0  173.0   98.0   88.0\n",
      "25     2   45.0  345.0   55.0   69.0   85.0  107.0   60.0   71.0\n",
      "26     3   22.0  234.0   36.0   26.0   36.0   55.0   20.0   40.0\n",
      "27     3   14.0  321.0   27.0   24.0   39.0   46.0   11.0   51.0\n",
      "28     3  136.0  220.0   90.0  159.0  162.0  252.0  166.0  118.0\n",
      "29     3  277.0  342.0  133.0  310.0  199.0  409.0  325.0  176.0\n",
      "30     3   68.0  373.0   42.0   79.0   75.0  118.0   69.0   62.0\n",
      "31     3   14.0  497.0   46.0   34.0   87.0   72.0   19.0   63.0\n",
      "32     3  105.0  133.0   49.0  119.0   81.0  160.0  122.0   74.0\n",
      "33     3   39.0  202.0   51.0   45.0   75.0  105.0   37.0   84.0\n",
      "34     3   94.0  111.0   52.0  110.0   91.0  153.0  118.0   79.0\n",
      "35     4   60.0  199.0   65.0   80.0   88.0  139.0   71.0   75.0\n",
      "36     4   60.0  315.0   45.0   77.0  101.0  117.0   68.0   79.0\n",
      "37     4   33.0  422.0   39.0   49.0   61.0   80.0   49.0   73.0\n",
      "38     4  134.0  197.0  101.0  134.0  219.0  224.0  123.0  101.0\n",
      "39     4   35.0   34.0   13.0   20.0   28.0   28.0   37.0   23.0\n",
      "40     4   36.0  339.0   33.0   67.0   57.0  101.0   42.0   66.0\n",
      "41     4   11.0    9.0    2.0    7.0    3.0    6.0   16.0    4.0\n",
      "42     4   24.0  314.0   33.0   39.0   78.0   71.0   33.0   54.0\n",
      "43     5   19.0  338.0   64.0   39.0   83.0   99.0   25.0   82.0\n",
      "44     5   53.0  331.0   52.0   73.0   90.0  122.0   57.0   72.0\n",
      "45     5   59.0  227.0   56.0   69.0  120.0  113.0   56.0  152.0\n",
      "46     5  100.0  389.0  103.0  153.0  204.0  225.0  117.0  133.0\n",
      "47     5   22.0  269.0   65.0   34.0   83.0   90.0   22.0  122.0\n",
      "48     5   92.0  104.0   48.0   89.0   80.0  145.0   91.0   51.0\n",
      "49     5   22.0  293.0   28.0   21.0   39.0   48.0   34.0   34.0\n",
      "50     5   43.0  343.0   41.0   54.0   79.0   90.0   56.0   70.0\n"
     ]
    }
   ],
   "source": [
    "# creating df object with columns specified   \n",
    "csv = pd.DataFrame(X_test, columns =list(range(number_of_clusters))) \n",
    "\n",
    "#Adding Lables to the Data Frame\n",
    "\n",
    "csv.insert(0, \"class\", Y_test)\n",
    "print(csv)\n",
    "\n",
    "\n",
    "csv.to_csv (r'../outputs/test.csv', index = None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223, 8)\n",
      "(51, 8)\n"
     ]
    }
   ],
   "source": [
    "# Read from CVS File\n",
    "df = pd.read_csv('../outputs/train.csv')\n",
    "# print(df)\n",
    "\n",
    "\n",
    "classes_train=df.loc[:,\"class\"]\n",
    "# classes_train = classes_train.to_numpy()\n",
    "# print(classes_train)\n",
    "# print(np.shape(classes_train))\n",
    "\n",
    "\n",
    "features_train=df.loc[:, df.columns != 'class']\n",
    "# features_train = features_train.to_numpy()\n",
    "# print(features_train)\n",
    "print(np.shape(features_train))\n",
    "\n",
    "# Read from CVS File\n",
    "df = pd.read_csv('../outputs/test.csv')\n",
    "# print(df)\n",
    "\n",
    "\n",
    "classes_test=df.loc[:,\"class\"]\n",
    "# classes_test = classes_test.to_numpy()\n",
    "# print(classes_test)\n",
    "# print(np.shape(classes_test))\n",
    "\n",
    "\n",
    "features_test=df.loc[:, df.columns != 'class']\n",
    "# features_test = features_test.to_numpy()\n",
    "# print(features_test)\n",
    "print(np.shape(features_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Visual Words(BoVW)\n",
    "##### SIFT TO SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, actual = train_randomforest(features_train,classes_train,features_test,classes_test)\n",
    "# prediction, actual = train_svm(features_train,classes_train,features_test,classes_test)\n",
    "\n",
    "# prediction, actual = train_randomforest(X_train,Y_train,X_test,Y_test)\n",
    "\n",
    "# print(prediction)\n",
    "# print(actual)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27450980392156865\n"
     ]
    }
   ],
   "source": [
    "accuracy = performance_analysis(prediction,actual)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
