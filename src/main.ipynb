{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import*\n",
    "# from preprocessing import Get_Hand,preprocessing_hagrass_eq_s,Cut_pre\n",
    "from preprocessing_new import preprocessing_new_1\n",
    "from feature_extraction import extract_features,read_images\n",
    "from training import *\n",
    "from performance import performance_analysis\n",
    "from itertools import compress\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vector_train=np.array([])\n",
    "Y_train=np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vector_test=np.array([])\n",
    "Y_test=np.array([])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "1\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "2\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "3\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "4\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "5\n",
      "The new directory is created!\n",
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "#Training Data Set\n",
    "for i in range(0, 6):\n",
    "    print(i)\n",
    "    path_of_the_directory='../data_split/split/men/train/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/men/train/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    else:\n",
    "        shutil.rmtree(path_of_the_directory_result, ignore_errors=False, onerror=None)\n",
    "        os.mkdir(path_of_the_directory_result)\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str(filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing_new_1(img)\n",
    "\n",
    "        # binary_hand=Get_Hand(img)\n",
    "        # binary_hand=preprocessing_hagrass_eq_s(img)\n",
    "        # binary_hand=preRGB(img)\n",
    "        # binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        # binary_hand=preprocessing2(img)\n",
    "        \n",
    "        # OCR,binary_hand=Cut_pre(img)\n",
    "        # features_vector_train=OCR(features_vector_train,binary_hand,filename)\n",
    "        # features_vector_train=np.append(features_vector_train,OCR)\n",
    "        # Y_train=np.append(Y_train,i)\n",
    "        # print(features_vector_train)\n",
    "        # print(Y_train)\n",
    "\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)\n",
    "\n",
    "    path_of_the_directory='../data_split/split/women/train/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/women/train/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str(filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing_new_1(img)\n",
    "\n",
    "        # binary_hand=Get_Hand(img)\n",
    "        # binary_hand=preprocessing_hagrass_eq_s(img)\n",
    "        # binary_hand=preRGB(img)\n",
    "        # features_vector_train=OCR(features_vector_train,binary_hand,filename)\n",
    "        # Y_train=np.append(Y_train,i)\n",
    "        # binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        # binary_hand=preprocessing2(img)\n",
    "\n",
    "\n",
    "        # OCR,binary_hand=Cut_pre(img)\n",
    "        # features_vector_train=OCR(features_vector_train,binary_hand,filename)\n",
    "        # features_vector_train=np.append(features_vector_train,OCR)\n",
    "        # Y_train=np.append(Y_train,i)\n",
    "        # print(features_vector_train)\n",
    "        # print(Y_train)\n",
    "        \n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "1\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "2\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "3\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "4\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "5\n",
      "The new directory is created!\n",
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "#Testing Data Set\n",
    "for i in range(0, 6):\n",
    "    print(i)\n",
    "    path_of_the_directory='../data_split/split/men/test/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/men/test/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str(filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing_new_1(img)\n",
    "        # binary_hand=Get_Hand(img)\n",
    "        # binary_hand=preprocessing_hagrass_eq_s(img)\n",
    "        # binary_hand=preRGB(img)\n",
    "        # features_vector_test=OCR(features_vector_test,binary_hand,filename)\n",
    "        # Y_test=np.append(Y_test,i)\n",
    "        # binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        # binary_hand=preprocessing2(img)\n",
    "        # OCR,binary_hand=Cut_pre(img)\n",
    "        # features_vector_train=OCR(features_vector_train,binary_hand,filename)\n",
    "        # features_vector_test=np.append(features_vector_test,OCR)\n",
    "        # Y_test=np.append(Y_test,i)\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)\n",
    "\n",
    "    path_of_the_directory='../data_split/split/women/test/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/women/test/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str( filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing_new_1(img)\n",
    "        # binary_hand=Get_Hand(img)\n",
    "        # binary_hand=preprocessing_hagrass_eq_s(img)\n",
    "        # binary_hand=preRGB(img)\n",
    "        # features_vector_test=OCR(features_vector_test,binary_hand,filename)\n",
    "        # Y_test=np.append(Y_test,i)\n",
    "        # binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        # binary_hand=preprocessing2(img)\n",
    "        # OCR,binary_hand=Cut_pre(img)\n",
    "        # features_vector_train=OCR(features_vector_train,binary_hand,filename)\n",
    "        # features_vector_test=np.append(features_vector_test,OCR)\n",
    "        # Y_test=np.append(Y_test,i)\n",
    "        \n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', 'region']\n",
      "['0', '1', '2', '3', '4', '5', 'region']\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Read 0: (200, 188, 314)\n",
      "Read 1: (210, 188, 314)\n",
      "Read 2: (215, 188, 314)\n",
      "Read 3: (221, 188, 314)\n",
      "Read 4: (210, 188, 314)\n",
      "Read 5: (217, 188, 314)\n",
      "['0', '1', '2', '3', '4', '5', 'region']\n",
      "['0', '1', '2', '3', '4', '5', 'region']\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Read 0: (30, 188, 314)\n",
      "Read 1: (31, 188, 314)\n",
      "Read 2: (34, 188, 314)\n",
      "Read 3: (34, 188, 314)\n",
      "Read 4: (33, 188, 314)\n",
      "Read 5: (33, 188, 314)\n"
     ]
    }
   ],
   "source": [
    "# Step(1) Read Images\n",
    "path='../outputs/preprocessing_output/'\n",
    "train_images=read_images(path,type=\"train\")\n",
    "\n",
    "print(\"Read 0:\", np.shape(train_images['0']))\n",
    "print(\"Read 1:\", np.shape(train_images['1']))\n",
    "print(\"Read 2:\", np.shape(train_images['2']))\n",
    "print(\"Read 3:\", np.shape(train_images['3']))\n",
    "print(\"Read 4:\", np.shape(train_images['4']))\n",
    "print(\"Read 5:\", np.shape(train_images['5']))\n",
    "\n",
    "\n",
    "test_images=read_images(path,type=\"test\")\n",
    "\n",
    "print(\"Read 0:\", np.shape(test_images['0']))\n",
    "print(\"Read 1:\", np.shape(test_images['1']))\n",
    "print(\"Read 2:\", np.shape(test_images['2']))\n",
    "print(\"Read 3:\", np.shape(test_images['3']))\n",
    "print(\"Read 4:\", np.shape(test_images['4']))\n",
    "print(\"Read 5:\", np.shape(test_images['5']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Key Points Detected Dropped\n",
      "No Key Points Detected Dropped\n",
      "No Key Points Detected Dropped\n",
      "No Key Points Detected Dropped\n",
      "No Key Points Detected Dropped\n",
      "No Key Points Detected Dropped\n",
      "No Key Points Detected Dropped\n",
      "No Key Points Detected Dropped\n",
      "No Key Points Detected Dropped\n",
      "Description Done\n",
      "Kmeans DONE\n",
      "Feature vector DONE\n"
     ]
    }
   ],
   "source": [
    "number_of_clusters=8\n",
    "path='../outputs/preprocessing_output/'\n",
    "X_train,Y_train,visual_words=extract_features(path,number_of_clusters,debug=True,images=train_images,train=True,visual_words=None)\n",
    "# print(np.shape(visual_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating df object with columns specified   \n",
    "csv = pd.DataFrame(X_train, columns =list(range(number_of_clusters))) \n",
    "\n",
    "# #Adding Lables to the Data Frame\n",
    "csv.insert(0, \"class\", Y_train)\n",
    "# print(csv)\n",
    "\n",
    "\n",
    "csv.to_csv (r'../outputs/train.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Key Points Detected Dropped\n",
      "No Key Points Detected Dropped\n",
      "Description Done\n",
      "Kmeans DONE\n",
      "Feature vector DONE\n"
     ]
    }
   ],
   "source": [
    "path='../outputs/preprocessing_output/'\n",
    "X_test,Y_test,visual_words=extract_features(path,clusters=None,debug=True,images=test_images,train=False,visual_words=visual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    class     0     1     2     3     4     5     6     7\n",
      "0       0  39.0  40.0  19.0  50.0  16.0  63.0   2.0  44.0\n",
      "1       0  18.0  25.0  12.0  24.0  10.0  66.0   1.0  18.0\n",
      "2       0  60.0  50.0  67.0  51.0  31.0  25.0  14.0  42.0\n",
      "3       0  38.0  35.0  36.0  78.0  30.0  44.0  26.0  62.0\n",
      "4       0  40.0  49.0  51.0  31.0  17.0  17.0  25.0  25.0\n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
      "188     5  62.0  28.0  44.0  22.0  38.0  29.0  61.0  11.0\n",
      "189     5  60.0  45.0  30.0  41.0  24.0  57.0  15.0   9.0\n",
      "190     5  87.0  29.0  50.0  52.0  52.0  25.0  25.0  31.0\n",
      "191     5  63.0  31.0  53.0  70.0  69.0  30.0  63.0  30.0\n",
      "192     5  44.0  46.0  31.0  29.0  37.0  56.0   9.0  22.0\n",
      "\n",
      "[193 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# creating df object with columns specified   \n",
    "csv = pd.DataFrame(X_test, columns =list(range(number_of_clusters))) \n",
    "\n",
    "#Adding Lables to the Data Frame\n",
    "\n",
    "csv.insert(0, \"class\", Y_test)\n",
    "print(csv)\n",
    "\n",
    "\n",
    "csv.to_csv (r'../outputs/test.csv', index = None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1264, 8)\n",
      "(193, 8)\n"
     ]
    }
   ],
   "source": [
    "# Read from CVS File\n",
    "df = pd.read_csv('../outputs/train.csv')\n",
    "# print(df)\n",
    "\n",
    "\n",
    "classes_train=df.loc[:,\"class\"]\n",
    "# classes_train = classes_train.to_numpy()\n",
    "# print(classes_train)\n",
    "# print(np.shape(classes_train))\n",
    "\n",
    "\n",
    "features_train=df.loc[:, df.columns != 'class']\n",
    "# features_train = features_train.to_numpy()\n",
    "# print(features_train)\n",
    "print(np.shape(features_train))\n",
    "\n",
    "# Read from CVS File\n",
    "df = pd.read_csv('../outputs/test.csv')\n",
    "# print(df)\n",
    "\n",
    "\n",
    "classes_test=df.loc[:,\"class\"]\n",
    "# classes_test = classes_test.to_numpy()\n",
    "# print(classes_test)\n",
    "# print(np.shape(classes_test))\n",
    "\n",
    "\n",
    "features_test=df.loc[:, df.columns != 'class']\n",
    "# features_test = features_test.to_numpy()\n",
    "# print(features_test)\n",
    "print(np.shape(features_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Visual Words(BoVW)\n",
    "##### SIFT TO SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, actual = train_randomforest(features_train,classes_train,features_test,classes_test)\n",
    "accuracy_RF = performance_analysis(prediction,actual)\n",
    "\n",
    "prediction, actual = train_svm(features_train,classes_train,features_test,classes_test)\n",
    "accuracy_SVM = performance_analysis(prediction,actual)\n",
    "\n",
    "# prediction, actual = train_randomforest(features_vector_train,Y_train,features_vector_test,Y_test)\n",
    "# accuracy_RF = performance_analysis(prediction,actual)\n",
    "\n",
    "# prediction, actual = train_svm(features_vector_train,Y_train,features_vector_test,Y_test)\n",
    "# accuracy_SVM = performance_analysis(prediction,actual)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(prediction)\n",
    "# print(actual)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_RF 0.36787564766839376\n",
      "accuracy_SVM 0.35233160621761656\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_RF\",accuracy_RF)\n",
    "print(\"accuracy_SVM\",accuracy_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
