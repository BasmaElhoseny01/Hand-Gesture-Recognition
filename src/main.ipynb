{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import*\n",
    "from preprocessing import preprocessing\n",
    "from feature_extraction import extract_features,read_images\n",
    "from training import *\n",
    "from performance import performance_analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "The new directory is created!\n",
      "2\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "3\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "4\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "5\n",
      "The new directory is created!\n",
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "#Training Data Set\n",
    "for i in range(0, 6):\n",
    "    print(i)\n",
    "    path_of_the_directory='../data_simple/split/men/train/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/men/train/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    else:\n",
    "        shutil.rmtree(path_of_the_directory_result, ignore_errors=False, onerror=None)\n",
    "        os.mkdir(path_of_the_directory_result)\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str(filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)\n",
    "\n",
    "    path_of_the_directory='../data_simple/split/women/train/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/women/train/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str( filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "1\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "2\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "3\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "4\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "5\n",
      "The new directory is created!\n",
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "#Testing Data Set\n",
    "for i in range(0, 6):\n",
    "    print(i)\n",
    "    path_of_the_directory='../data_simple/split/men/test/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/men/test/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str(filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)\n",
    "\n",
    "    path_of_the_directory='../data_simple/split/women/test/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/women/test/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str( filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Read 0: (2, 2592, 4608)\n",
      "Read 1: (3, 2592, 4608)\n",
      "Read 2: (3, 2592, 4608)\n",
      "Read 3: (4, 2592, 4608)\n",
      "Read 4: (3, 2592, 4608)\n",
      "Read 5: (3, 2592, 4608)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Read 0: (2, 2592, 4608)\n",
      "Read 1: (2, 2592, 4608)\n",
      "Read 2: (2, 2592, 4608)\n",
      "Read 3: (2, 2592, 4608)\n",
      "Read 4: (2, 2592, 4608)\n",
      "Read 5: (2, 2592, 4608)\n"
     ]
    }
   ],
   "source": [
    "# Step(1) Read Images\n",
    "path='../outputs/preprocessing_output/'\n",
    "train_images=read_images(path,type=\"train\")\n",
    "\n",
    "print(\"Read 0:\", np.shape(train_images['0']))\n",
    "print(\"Read 1:\", np.shape(train_images['1']))\n",
    "print(\"Read 2:\", np.shape(train_images['2']))\n",
    "print(\"Read 3:\", np.shape(train_images['3']))\n",
    "print(\"Read 4:\", np.shape(train_images['4']))\n",
    "print(\"Read 5:\", np.shape(train_images['5']))\n",
    "\n",
    "\n",
    "test_images=read_images(path,type=\"test\")\n",
    "\n",
    "print(\"Read 0:\", np.shape(test_images['0']))\n",
    "print(\"Read 1:\", np.shape(test_images['1']))\n",
    "print(\"Read 2:\", np.shape(test_images['2']))\n",
    "print(\"Read 3:\", np.shape(test_images['3']))\n",
    "print(\"Read 4:\", np.shape(test_images['4']))\n",
    "print(\"Read 5:\", np.shape(test_images['5']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift_descriptors for 0\n",
      "0 has: 492Keypoints\n",
      "1 has: 597Keypoints\n",
      "sift_descriptors for 1\n",
      "0 has: 308Keypoints\n",
      "1 has: 534Keypoints\n",
      "2 has: 754Keypoints\n",
      "sift_descriptors for 2\n",
      "0 has: 909Keypoints\n",
      "1 has: 736Keypoints\n",
      "2 has: 496Keypoints\n",
      "sift_descriptors for 3\n",
      "0 has: 1398Keypoints\n",
      "1 has: 338Keypoints\n",
      "2 has: 1112Keypoints\n",
      "3 has: 519Keypoints\n",
      "sift_descriptors for 4\n",
      "0 has: 883Keypoints\n",
      "1 has: 965Keypoints\n",
      "2 has: 1097Keypoints\n",
      "sift_descriptors for 5\n",
      "0 has: 753Keypoints\n",
      "1 has: 1043Keypoints\n",
      "2 has: 625Keypoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2,)\n",
      "1 (3,)\n",
      "2 (3,)\n",
      "3 (4,)\n",
      "4 (3,)\n",
      "5 (3,)\n"
     ]
    }
   ],
   "source": [
    "number_of_clusters=8\n",
    "path='../outputs/preprocessing_output/'\n",
    "X_train,Y_train,visual_words=extract_features(path,number_of_clusters,debug=True,images=train_images,train=True,visual_words=None)\n",
    "# print(np.shape(visual_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class      0      1      2      3      4      5      6      7\n",
      "0      0   53.0  216.0   16.0   18.0   78.0   35.0   20.0   56.0\n",
      "1      0   89.0  136.0   46.0   62.0   92.0   59.0   36.0   77.0\n",
      "2      1   60.0   38.0   17.0   24.0   47.0   33.0   15.0   74.0\n",
      "3      1   70.0  213.0   26.0   26.0   60.0   46.0   27.0   66.0\n",
      "4      1  132.0  214.0   56.0   60.0   66.0   78.0   57.0   91.0\n",
      "5      2  162.0  160.0   80.0   93.0   89.0   92.0   88.0  145.0\n",
      "6      2  136.0  117.0   56.0   54.0   75.0   92.0   56.0  150.0\n",
      "7      2   62.0  213.0   24.0   22.0   49.0   43.0   21.0   62.0\n",
      "8      3  280.0  269.0  160.0  167.0   94.0  112.0  170.0  146.0\n",
      "9      3   56.0   66.0   36.0   27.0   45.0   31.0   32.0   45.0\n",
      "10     3  204.0  213.0  126.0  157.0   99.0   58.0  150.0  105.0\n",
      "11     3   97.0   68.0   68.0   66.0   30.0   44.0   63.0   83.0\n",
      "12     4  151.0  235.0   67.0   88.0   80.0   74.0   84.0  104.0\n",
      "13     4  190.0  116.0  121.0  146.0   88.0   76.0  113.0  115.0\n",
      "14     4  184.0  251.0   56.0   64.0  168.0  121.0   70.0  183.0\n",
      "15     5   98.0  317.0   21.0   26.0   77.0   81.0   26.0  107.0\n",
      "16     5  125.0  419.0   46.0   58.0  100.0   85.0   49.0  161.0\n",
      "17     5   98.0  189.0   36.0   43.0   84.0   65.0   26.0   84.0\n"
     ]
    }
   ],
   "source": [
    "# creating df object with columns specified   \n",
    "csv = pd.DataFrame(X_train, columns =list(range(number_of_clusters))) \n",
    "\n",
    "# #Adding Lables to the Data Frame\n",
    "csv.insert(0, \"class\", Y_train)\n",
    "# print(csv)\n",
    "\n",
    "\n",
    "csv.to_csv (r'../outputs/train.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift_descriptors for 0\n",
      "0 has: 616Keypoints\n",
      "1 has: 480Keypoints\n",
      "sift_descriptors for 1\n",
      "0 has: 621Keypoints\n",
      "1 has: 74Keypoints\n",
      "sift_descriptors for 2\n",
      "0 has: 680Keypoints\n",
      "1 has: 591Keypoints\n",
      "sift_descriptors for 3\n",
      "0 has: 771Keypoints\n",
      "1 has: 981Keypoints\n",
      "sift_descriptors for 4\n",
      "0 has: 750Keypoints\n",
      "1 has: 798Keypoints\n",
      "sift_descriptors for 5\n",
      "0 has: 596Keypoints\n",
      "1 has: 1004Keypoints\n",
      "0 (2,)\n",
      "1 (2,)\n",
      "2 (2,)\n",
      "3 (2,)\n",
      "4 (2,)\n",
      "5 (2,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    }
   ],
   "source": [
    "path='../outputs/preprocessing_output/'\n",
    "X_test,Y_test,visual_words=extract_features(path,clusters=None,debug=True,images=test_images,train=False,visual_words=visual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class      0      1     2     3      4      5     6      7\n",
      "0      0   88.0  200.0  42.0  40.0   73.0   58.0  37.0   78.0\n",
      "1      0   56.0  189.0  19.0  21.0   63.0   44.0  14.0   74.0\n",
      "2      1   84.0  216.0  37.0  50.0   66.0   44.0  42.0   82.0\n",
      "3      1   13.0   11.0   9.0  11.0   11.0    4.0   9.0    6.0\n",
      "4      2   61.0  406.0  29.0  28.0   43.0   32.0  19.0   62.0\n",
      "5      2   62.0  294.0  11.0  14.0   54.0   53.0  14.0   89.0\n",
      "6      3   92.0  380.0  41.0  41.0   46.0   42.0  52.0   77.0\n",
      "7      3  150.0  310.0  79.0  88.0   79.0   85.0  68.0  122.0\n",
      "8      4   77.0  356.0  19.0  19.0   88.0   72.0  14.0  105.0\n",
      "9      4  121.0  253.0  49.0  62.0   96.0   79.0  49.0   89.0\n",
      "10     5   65.0  316.0  20.0  18.0   52.0   45.0  22.0   58.0\n",
      "11     5  137.0  366.0  46.0  46.0  128.0  114.0  34.0  133.0\n"
     ]
    }
   ],
   "source": [
    "# creating df object with columns specified   \n",
    "csv = pd.DataFrame(X_test, columns =list(range(number_of_clusters))) \n",
    "\n",
    "#Adding Lables to the Data Frame\n",
    "\n",
    "csv.insert(0, \"class\", Y_test)\n",
    "print(csv)\n",
    "\n",
    "\n",
    "csv.to_csv (r'../outputs/test.csv', index = None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from CVS File\n",
    "df = pd.read_csv('../outputs/features.csv')\n",
    "# print(df)\n",
    "\n",
    "\n",
    "classes=df.loc[:,\"class\"]\n",
    "classes = classes.to_numpy()\n",
    "# print(classes)\n",
    "# print(np.shape(classes))\n",
    "\n",
    "\n",
    "features=df.loc[:, df.columns != 'class']\n",
    "features = features.to_numpy()\n",
    "# print(features)\n",
    "# print(np.shape(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, actual = train_svm(X_train,Y_train,X_test,Y_test)\n",
    "# prediction, actual = train_randomforest(X_train,Y_train,X_test,Y_test)\n",
    "\n",
    "# print(prediction)\n",
    "# print(actual)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "accuracy = performance_analysis(prediction,actual)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
