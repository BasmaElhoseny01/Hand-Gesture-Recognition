{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import*\n",
    "from preprocessing import preprocessing,preprocessing2\n",
    "from feature_extraction import extract_features,read_images\n",
    "from training import *\n",
    "from performance import performance_analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "1\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "2\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "3\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "4\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "5\n",
      "The new directory is created!\n",
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "#Training Data Set\n",
    "for i in range(0, 6):\n",
    "    print(i)\n",
    "    path_of_the_directory='../data_simple/split/men/train/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/men/train/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    else:\n",
    "        shutil.rmtree(path_of_the_directory_result, ignore_errors=False, onerror=None)\n",
    "        os.mkdir(path_of_the_directory_result)\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str(filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        # binary_hand=preprocessing2(img)\n",
    "\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)\n",
    "\n",
    "    path_of_the_directory='../data_simple/split/women/train/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/women/train/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str(filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        # binary_hand=preprocessing2(img)\n",
    "\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "1\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "2\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "3\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "4\n",
      "The new directory is created!\n",
      "The new directory is created!\n",
      "5\n",
      "The new directory is created!\n",
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "#Testing Data Set\n",
    "for i in range(0, 6):\n",
    "    print(i)\n",
    "    path_of_the_directory='../data_simple/split/men/test/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/men/test/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str(filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        # binary_hand=preprocessing2(img)\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)\n",
    "\n",
    "    path_of_the_directory='../data_simple/split/women/test/'+str(i)+'/'\n",
    "    path_of_the_directory_result='../outputs/preprocessing_output/women/test/'+str(i)+'/'\n",
    "    isExist = os.path.exists(path_of_the_directory_result)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_of_the_directory_result)\n",
    "        print(\"The new directory is created!\")\n",
    "    # ind=0\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        # if(ind>20):\n",
    "        #     break\n",
    "        # ind=ind+1\n",
    "        img = cv2.imread(path_of_the_directory+str( filename))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Skin Masks\n",
    "        binary_hand=preprocessing(img, gamma=True, close=True)\n",
    "        # binary_hand=preprocessing2(img)\n",
    "        cv2.imwrite(path_of_the_directory_result+filename,binary_hand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Read 0: (24, 2592, 4608)\n",
      "Read 1: (23, 2592, 4608)\n",
      "Read 2: (26, 2592, 4608)\n",
      "Read 3: (24, 2592, 4608)\n",
      "Read 4: (22, 2592, 4608)\n",
      "Read 5: (26, 2592, 4608)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Read 0: (6, 2592, 4608)\n",
      "Read 1: (4, 2592, 4608)\n",
      "Read 2: (5, 2592, 4608)\n",
      "Read 3: (6, 2592, 4608)\n",
      "Read 4: (4, 2592, 4608)\n",
      "Read 5: (6, 2592, 4608)\n"
     ]
    }
   ],
   "source": [
    "# Step(1) Read Images\n",
    "path='../outputs/preprocessing_output/'\n",
    "train_images=read_images(path,type=\"train\")\n",
    "\n",
    "print(\"Read 0:\", np.shape(train_images['0']))\n",
    "print(\"Read 1:\", np.shape(train_images['1']))\n",
    "print(\"Read 2:\", np.shape(train_images['2']))\n",
    "print(\"Read 3:\", np.shape(train_images['3']))\n",
    "print(\"Read 4:\", np.shape(train_images['4']))\n",
    "print(\"Read 5:\", np.shape(train_images['5']))\n",
    "\n",
    "\n",
    "test_images=read_images(path,type=\"test\")\n",
    "\n",
    "print(\"Read 0:\", np.shape(test_images['0']))\n",
    "print(\"Read 1:\", np.shape(test_images['1']))\n",
    "print(\"Read 2:\", np.shape(test_images['2']))\n",
    "print(\"Read 3:\", np.shape(test_images['3']))\n",
    "print(\"Read 4:\", np.shape(test_images['4']))\n",
    "print(\"Read 5:\", np.shape(test_images['5']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift_descriptors for 0\n",
      "0 has: 630Keypoints\n",
      "1 has: 496Keypoints\n",
      "2 has: 1030Keypoints\n",
      "3 has: 550Keypoints\n",
      "4 has: 502Keypoints\n",
      "5 has: 1250Keypoints\n",
      "6 has: 690Keypoints\n",
      "7 has: 742Keypoints\n",
      "8 has: 492Keypoints\n",
      "9 has: 633Keypoints\n",
      "10 has: 952Keypoints\n",
      "11 has: 580Keypoints\n",
      "12 has: 417Keypoints\n",
      "13 has: 659Keypoints\n",
      "14 has: 717Keypoints\n",
      "15 has: 794Keypoints\n",
      "16 has: 689Keypoints\n",
      "17 has: 548Keypoints\n",
      "18 has: 729Keypoints\n",
      "19 has: 474Keypoints\n",
      "20 has: 495Keypoints\n",
      "21 has: 514Keypoints\n",
      "22 has: 483Keypoints\n",
      "23 has: 327Keypoints\n",
      "sift_descriptors for 1\n",
      "0 has: 512Keypoints\n",
      "1 has: 462Keypoints\n",
      "2 has: 458Keypoints\n",
      "3 has: 301Keypoints\n",
      "4 has: 711Keypoints\n",
      "5 has: 429Keypoints\n",
      "6 has: 882Keypoints\n",
      "7 has: 547Keypoints\n",
      "8 has: 688Keypoints\n",
      "9 has: 665Keypoints\n",
      "10 has: 517Keypoints\n",
      "11 has: 934Keypoints\n",
      "12 has: 750Keypoints\n",
      "13 has: 707Keypoints\n",
      "14 has: 713Keypoints\n",
      "15 has: 74Keypoints\n",
      "16 has: 1431Keypoints\n",
      "17 has: 850Keypoints\n",
      "18 has: 545Keypoints\n",
      "19 has: 699Keypoints\n",
      "20 has: 553Keypoints\n",
      "21 has: 747Keypoints\n",
      "22 has: 886Keypoints\n",
      "sift_descriptors for 2\n",
      "0 has: 712Keypoints\n",
      "1 has: 771Keypoints\n",
      "2 has: 1178Keypoints\n",
      "3 has: 204Keypoints\n",
      "4 has: 994Keypoints\n",
      "5 has: 610Keypoints\n",
      "6 has: 636Keypoints\n",
      "7 has: 856Keypoints\n",
      "8 has: 818Keypoints\n",
      "9 has: 920Keypoints\n",
      "10 has: 686Keypoints\n",
      "11 has: 762Keypoints\n",
      "12 has: 604Keypoints\n",
      "13 has: 578Keypoints\n",
      "14 has: 475Keypoints\n",
      "15 has: 701Keypoints\n",
      "16 has: 486Keypoints\n",
      "17 has: 779Keypoints\n",
      "18 has: 888Keypoints\n",
      "19 has: 919Keypoints\n",
      "20 has: 585Keypoints\n",
      "21 has: 596Keypoints\n",
      "22 has: 444Keypoints\n",
      "23 has: 776Keypoints\n",
      "24 has: 716Keypoints\n",
      "25 has: 228Keypoints\n",
      "sift_descriptors for 3\n",
      "0 has: 801Keypoints\n",
      "1 has: 469Keypoints\n",
      "2 has: 1618Keypoints\n",
      "3 has: 892Keypoints\n",
      "4 has: 278Keypoints\n",
      "5 has: 288Keypoints\n",
      "6 has: 953Keypoints\n",
      "7 has: 495Keypoints\n",
      "8 has: 1106Keypoints\n",
      "9 has: 338Keypoints\n",
      "10 has: 810Keypoints\n",
      "11 has: 1194Keypoints\n",
      "12 has: 655Keypoints\n",
      "13 has: 771Keypoints\n",
      "14 has: 951Keypoints\n",
      "15 has: 832Keypoints\n",
      "16 has: 916Keypoints\n",
      "17 has: 540Keypoints\n",
      "18 has: 868Keypoints\n",
      "19 has: 567Keypoints\n",
      "20 has: 677Keypoints\n",
      "21 has: 637Keypoints\n",
      "22 has: 384Keypoints\n",
      "23 has: 518Keypoints\n",
      "sift_descriptors for 4\n",
      "0 has: 1106Keypoints\n",
      "1 has: 504Keypoints\n",
      "2 has: 1448Keypoints\n",
      "3 has: 242Keypoints\n",
      "4 has: 934Keypoints\n",
      "5 has: 1611Keypoints\n",
      "6 has: 504Keypoints\n",
      "7 has: 950Keypoints\n",
      "8 has: 1227Keypoints\n",
      "9 has: 1020Keypoints\n",
      "10 has: 731Keypoints\n",
      "11 has: 750Keypoints\n",
      "12 has: 629Keypoints\n",
      "13 has: 132Keypoints\n",
      "14 has: 888Keypoints\n",
      "15 has: 845Keypoints\n",
      "16 has: 706Keypoints\n",
      "17 has: 1189Keypoints\n",
      "18 has: 793Keypoints\n",
      "19 has: 557Keypoints\n",
      "20 has: 893Keypoints\n",
      "21 has: 1003Keypoints\n",
      "sift_descriptors for 5\n",
      "0 has: 642Keypoints\n",
      "1 has: 942Keypoints\n",
      "2 has: 760Keypoints\n",
      "3 has: 1109Keypoints\n",
      "4 has: 754Keypoints\n",
      "5 has: 292Keypoints\n",
      "6 has: 778Keypoints\n",
      "7 has: 269Keypoints\n",
      "8 has: 1553Keypoints\n",
      "9 has: 935Keypoints\n",
      "10 has: 38Keypoints\n",
      "11 has: 984Keypoints\n",
      "12 has: 993Keypoints\n",
      "13 has: 1471Keypoints\n",
      "14 has: 1237Keypoints\n",
      "15 has: 76Keypoints\n",
      "16 has: 45Keypoints\n",
      "17 has: 815Keypoints\n",
      "18 has: 869Keypoints\n",
      "19 has: 631Keypoints\n",
      "20 has: 942Keypoints\n",
      "21 has: 766Keypoints\n",
      "22 has: 1086Keypoints\n",
      "23 has: 659Keypoints\n",
      "24 has: 1023Keypoints\n",
      "25 has: 688Keypoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (24,)\n",
      "1 (23,)\n",
      "2 (26,)\n",
      "3 (24,)\n",
      "4 (22,)\n",
      "5 (26,)\n"
     ]
    }
   ],
   "source": [
    "number_of_clusters=8\n",
    "path='../outputs/preprocessing_output/'\n",
    "X_train,Y_train,visual_words=extract_features(path,number_of_clusters,debug=True,images=train_images,train=True,visual_words=None)\n",
    "# print(np.shape(visual_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating df object with columns specified   \n",
    "csv = pd.DataFrame(X_train, columns =list(range(number_of_clusters))) \n",
    "\n",
    "# #Adding Lables to the Data Frame\n",
    "csv.insert(0, \"class\", Y_train)\n",
    "# print(csv)\n",
    "\n",
    "\n",
    "csv.to_csv (r'../outputs/train.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift_descriptors for 0\n",
      "0 has: 493Keypoints\n",
      "1 has: 811Keypoints\n",
      "2 has: 753Keypoints\n",
      "3 has: 335Keypoints\n",
      "4 has: 739Keypoints\n"
     ]
    }
   ],
   "source": [
    "path='../outputs/preprocessing_output/'\n",
    "X_test,Y_test,visual_words=extract_features(path,clusters=None,debug=True,images=test_images,train=False,visual_words=visual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class      0      1      2      3      4      5      6      7\n",
      "0      0   51.0  140.0   41.0   55.0   83.0  105.0   51.0   62.0\n",
      "1      0  111.0  106.0   59.0  119.0  116.0  172.0  115.0  111.0\n",
      "2      0   77.0   32.0   22.0   75.0   46.0   99.0   74.0   34.0\n",
      "3      0  174.0  185.0  101.0  186.0  176.0  279.0  179.0  141.0\n",
      "4      0   71.0  270.0   91.0   94.0  146.0  182.0   70.0  119.0\n",
      "5      0   59.0   49.0   36.0   64.0   55.0   95.0   59.0   39.0\n",
      "6      0   44.0  221.0   50.0   62.0   76.0  102.0   37.0   87.0\n",
      "7      0   45.0   49.0   26.0   48.0   44.0   77.0   47.0   37.0\n",
      "8      0   26.0  194.0   53.0   40.0  135.0   93.0   31.0   84.0\n",
      "9      1   41.0  234.0   32.0   61.0   54.0   91.0   56.0   58.0\n",
      "10     1   86.0  121.0   49.0   95.0   70.0  139.0   94.0   72.0\n",
      "11     1   51.0   16.0   24.0   41.0   23.0   59.0   55.0   23.0\n",
      "12     1   36.0   35.0   26.0   52.0   36.0   72.0   49.0   21.0\n",
      "13     1  115.0  232.0   88.0  133.0  166.0  189.0  138.0  154.0\n",
      "14     1   78.0  188.0   80.0   93.0  111.0  164.0   95.0  134.0\n",
      "15     1   11.0   10.0    3.0   11.0    4.0   12.0   12.0   11.0\n",
      "16     1   30.0  255.0   25.0   33.0   43.0   57.0   29.0   50.0\n",
      "17     1   50.0  240.0   56.0   58.0  109.0  115.0   47.0   72.0\n",
      "18     2   14.0  354.0   48.0   17.0   63.0   76.0   11.0  104.0\n",
      "19     2   17.0  309.0   30.0   20.0   43.0   39.0   20.0   34.0\n",
      "20     2   26.0   14.0   15.0   23.0   38.0   40.0   24.0   24.0\n",
      "21     2   61.0  109.0   65.0   79.0  138.0  145.0   65.0   74.0\n",
      "22     2   46.0  137.0   53.0   57.0   94.0  104.0   68.0   77.0\n",
      "23     2   40.0  287.0   33.0   47.0   84.0   76.0   40.0   63.0\n",
      "24     2   90.0  215.0   75.0   99.0  135.0  173.0   98.0   88.0\n",
      "25     2   45.0  345.0   55.0   69.0   85.0  107.0   60.0   71.0\n",
      "26     3   22.0  234.0   36.0   26.0   36.0   55.0   20.0   40.0\n",
      "27     3   14.0  321.0   27.0   24.0   39.0   46.0   11.0   51.0\n",
      "28     3  136.0  220.0   90.0  159.0  162.0  252.0  166.0  118.0\n",
      "29     3  277.0  342.0  133.0  310.0  199.0  409.0  325.0  176.0\n",
      "30     3   68.0  373.0   42.0   79.0   75.0  118.0   69.0   62.0\n",
      "31     3   14.0  497.0   46.0   34.0   87.0   72.0   19.0   63.0\n",
      "32     3  105.0  133.0   49.0  119.0   81.0  160.0  122.0   74.0\n",
      "33     3   39.0  202.0   51.0   45.0   75.0  105.0   37.0   84.0\n",
      "34     3   94.0  111.0   52.0  110.0   91.0  153.0  118.0   79.0\n",
      "35     4   60.0  199.0   65.0   80.0   88.0  139.0   71.0   75.0\n",
      "36     4   60.0  315.0   45.0   77.0  101.0  117.0   68.0   79.0\n",
      "37     4   33.0  422.0   39.0   49.0   61.0   80.0   49.0   73.0\n",
      "38     4  134.0  197.0  101.0  134.0  219.0  224.0  123.0  101.0\n",
      "39     4   35.0   34.0   13.0   20.0   28.0   28.0   37.0   23.0\n",
      "40     4   36.0  339.0   33.0   67.0   57.0  101.0   42.0   66.0\n",
      "41     4   11.0    9.0    2.0    7.0    3.0    6.0   16.0    4.0\n",
      "42     4   24.0  314.0   33.0   39.0   78.0   71.0   33.0   54.0\n",
      "43     5   19.0  338.0   64.0   39.0   83.0   99.0   25.0   82.0\n",
      "44     5   53.0  331.0   52.0   73.0   90.0  122.0   57.0   72.0\n",
      "45     5   59.0  227.0   56.0   69.0  120.0  113.0   56.0  152.0\n",
      "46     5  100.0  389.0  103.0  153.0  204.0  225.0  117.0  133.0\n",
      "47     5   22.0  269.0   65.0   34.0   83.0   90.0   22.0  122.0\n",
      "48     5   92.0  104.0   48.0   89.0   80.0  145.0   91.0   51.0\n",
      "49     5   22.0  293.0   28.0   21.0   39.0   48.0   34.0   34.0\n",
      "50     5   43.0  343.0   41.0   54.0   79.0   90.0   56.0   70.0\n"
     ]
    }
   ],
   "source": [
    "# creating df object with columns specified   \n",
    "csv = pd.DataFrame(X_test, columns =list(range(number_of_clusters))) \n",
    "\n",
    "#Adding Lables to the Data Frame\n",
    "\n",
    "csv.insert(0, \"class\", Y_test)\n",
    "print(csv)\n",
    "\n",
    "\n",
    "csv.to_csv (r'../outputs/test.csv', index = None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223, 8)\n",
      "(51, 8)\n"
     ]
    }
   ],
   "source": [
    "# Read from CVS File\n",
    "df = pd.read_csv('../outputs/train.csv')\n",
    "# print(df)\n",
    "\n",
    "\n",
    "classes_train=df.loc[:,\"class\"]\n",
    "# classes_train = classes_train.to_numpy()\n",
    "# print(classes_train)\n",
    "# print(np.shape(classes_train))\n",
    "\n",
    "\n",
    "features_train=df.loc[:, df.columns != 'class']\n",
    "# features_train = features_train.to_numpy()\n",
    "# print(features_train)\n",
    "print(np.shape(features_train))\n",
    "\n",
    "# Read from CVS File\n",
    "df = pd.read_csv('../outputs/test.csv')\n",
    "# print(df)\n",
    "\n",
    "\n",
    "classes_test=df.loc[:,\"class\"]\n",
    "# classes_test = classes_test.to_numpy()\n",
    "# print(classes_test)\n",
    "# print(np.shape(classes_test))\n",
    "\n",
    "\n",
    "features_test=df.loc[:, df.columns != 'class']\n",
    "# features_test = features_test.to_numpy()\n",
    "# print(features_test)\n",
    "print(np.shape(features_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Visual Words(BoVW)\n",
    "##### SIFT TO SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, actual = train_randomforest(features_train,classes_train,features_test,classes_test)\n",
    "# prediction, actual = train_svm(features_train,classes_train,features_test,classes_test)\n",
    "\n",
    "# prediction, actual = train_randomforest(X_train,Y_train,X_test,Y_test)\n",
    "\n",
    "# print(prediction)\n",
    "# print(actual)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27450980392156865\n"
     ]
    }
   ],
   "source": [
    "accuracy = performance_analysis(prediction,actual)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
